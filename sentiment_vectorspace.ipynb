{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-24T22:29:27.898422Z",
     "start_time": "2024-07-24T22:29:24.503967Z"
    }
   },
   "source": [
    "import json\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "from itables import show\n",
    "from datetime import datetime, timezone\n",
    "import numpy as np\n",
    "# Preprocessing\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "# Sentiment Analysis\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lilynorthcutt/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/lilynorthcutt/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/lilynorthcutt/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T22:34:36.617674Z",
     "start_time": "2024-07-24T22:32:52.376418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test Transformers is properly installed\n",
    "!python3 -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))\""
   ],
   "id": "48d365a8b808ffb8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\r\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\r\n",
      "model.safetensors: 100%|█████████████████████| 268M/268M [01:39<00:00, 2.69MB/s]\r\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\r\n",
      "\r\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\r\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\r\n",
      "tokenizer_config.json: 100%|██████████████████| 48.0/48.0 [00:00<00:00, 997kB/s]\r\n",
      "vocab.txt: 100%|█████████████████████████████| 232k/232k [00:00<00:00, 4.82MB/s]\r\n",
      "[{'label': 'POSITIVE', 'score': 0.9998704195022583}]\r\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Preprocessing\n",
    "\n",
    "## Read in Data\n"
   ],
   "id": "68195676c01ac031"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T22:29:49.955873Z",
     "start_time": "2024-07-24T22:29:49.840762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Opening JSON file\n",
    "f = open('Data/incel_small.json')\n",
    "\n",
    "# Create a list of dictionaries\n",
    "data = json.load(f)\n",
    "f.close()\n",
    "\n",
    "# Create dataframe from list keeping columns of interest\n",
    "df = pd.DataFrame(data,\n",
    "  columns=['author', 'created_utc', 'num_comments', 'selftext', 'subreddit', 'title']) \n",
    "  \n",
    "# Convert unix to utc\n",
    "df[\"created_utc\"] = df[\"created_utc\"].apply(lambda time: datetime.fromtimestamp(time, tz=timezone.utc).strftime('%Y-%m-%d'))\n",
    "\n",
    "\n",
    "# lambda row: datetime.fromtimestamp(row[\"created_utc\"], tz=timezone.utc).strftime('%Y-%m-%d')\n",
    "show(df[[\"subreddit\", \"created_utc\", \"title\"]].head())"
   ],
   "id": "b888ecb86a741d95",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<table id=\"itables_f5c5e630_6f15_4556_813b_d82685d1a094\" class=\"display nowrap\" data-quarto-disable-processing=\"true\" style=\"table-layout:auto;width:auto;margin:auto;caption-side:bottom\">\n",
       "<thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      \n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead><tbody><tr>\n",
       "<td style=\"vertical-align:middle; text-align:left\">\n",
       "<div style=\"float:left; margin-right: 10px;\">\n",
       "<a href=https://mwouts.github.io/itables/><svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "width=\"64\" viewBox=\"0 0 500 400\" style=\"font-family: 'Droid Sans', sans-serif;\">\n",
       "    <g style=\"fill:#d9d7fc\">\n",
       "        <path d=\"M100,400H500V357H100Z\" />\n",
       "        <path d=\"M100,300H400V257H100Z\" />\n",
       "        <path d=\"M0,200H400V157H0Z\" />\n",
       "        <path d=\"M100,100H500V57H100Z\" />\n",
       "        <path d=\"M100,350H500V307H100Z\" />\n",
       "        <path d=\"M100,250H400V207H100Z\" />\n",
       "        <path d=\"M0,150H400V107H0Z\" />\n",
       "        <path d=\"M100,50H500V7H100Z\" />\n",
       "    </g>\n",
       "    <g style=\"fill:#1a1366;stroke:#1a1366;\">\n",
       "   <rect x=\"100\" y=\"7\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"0\" y=\"107\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"0;0;400\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"207\" width=\"300\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;300;0\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;400\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"307\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <g style=\"fill:transparent;stroke-width:8; stroke-linejoin:round\" rx=\"5\">\n",
       "            <g transform=\"translate(45 50) rotate(-45)\">\n",
       "                <circle r=\"33\" cx=\"0\" cy=\"0\" />\n",
       "                <rect x=\"-8\" y=\"32\" width=\"16\" height=\"30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(450 152)\">\n",
       "                <polyline points=\"-15,-20 -35,-20 -35,40 25,40 25,20\" />\n",
       "                <rect x=\"-15\" y=\"-40\" width=\"60\" height=\"60\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(50 352)\">\n",
       "                <polygon points=\"-35,-5 0,-40 35,-5\" />\n",
       "                <polygon points=\"-35,10 0,45 35,10\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(75 250)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(425 250) rotate(180)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "        </g>\n",
       "    </g>\n",
       "</svg>\n",
       "</a>\n",
       "</div>\n",
       "<div>\n",
       "Loading ITables v2.1.4 from the internet...\n",
       "(need <a href=https://mwouts.github.io/itables/troubleshooting.html>help</a>?)</td>\n",
       "</div>\n",
       "</tr></tbody>\n",
       "\n",
       "</table>\n",
       "<link href=\"https://www.unpkg.com/dt_for_itables@2.0.11/dt_bundle.css\" rel=\"stylesheet\">\n",
       "<script type=\"module\">\n",
       "    import {DataTable, jQuery as $} from 'https://www.unpkg.com/dt_for_itables@2.0.11/dt_bundle.js';\n",
       "\n",
       "    document.querySelectorAll(\"#itables_f5c5e630_6f15_4556_813b_d82685d1a094:not(.dataTable)\").forEach(table => {\n",
       "        // Define the table data\n",
       "        const data = [[\"Incels\", \"2017-11-03\", \"WONDERFUEL: Streamer accuses his girlfriend of cheating and acts in kind whilst live\"], [\"Incels\", \"2017-11-03\", \"Guide to Females\"], [\"Incels\", \"2017-11-03\", \"Incel? Chad? Something in between?\"], [\"Incels\", \"2017-11-03\", \"VENT I white knighted for a girl in class because she saw I had 2 bags off hot cheetos. I\\u2019m so sorry guys how could\\u2019ve I\\u2019ve been so stupid\"], [\"Incels\", \"2017-11-03\", \"Shame on me\"]];\n",
       "\n",
       "        // Define the dt_args\n",
       "        let dt_args = {\"layout\": {\"topStart\": null, \"topEnd\": null, \"bottomStart\": null, \"bottomEnd\": null}, \"order\": []};\n",
       "        dt_args[\"data\"] = data;\n",
       "\n",
       "        \n",
       "        new DataTable(table, dt_args);\n",
       "    });\n",
       "</script>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T22:30:16.071887Z",
     "start_time": "2024-07-24T22:30:16.067999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# A lot of posts do not have text, for many posts this is because the post text got removed or deleted\n",
    "print(f'Total submissions: {len(df)} \\nTotal submissions with post text: {np.size(df[\"selftext\"].unique()) -1}')\n"
   ],
   "id": "67a96f630017bf9d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total submissions: 5000 \n",
      "Total submissions with post text: 1857\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Cleaning\n",
   "id": "38a61c88863716b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T22:31:00.302615Z",
     "start_time": "2024-07-24T22:31:00.207393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "\n",
    "df['cleaned_title'] = df['title'].apply(lambda title: clean_text(str(title)))\n",
    "df['cleaned_text'] = df['selftext'].apply(lambda text: clean_text(str(text)))\n",
    "print(f'Title before cleaning: {df[\"title\"][0]} \\n\\nTitle after cleaning: {df[\"cleaned_title\"][0]}')"
   ],
   "id": "25b50d2eb3c59d33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title before cleaning: WONDERFUEL: Streamer accuses his girlfriend of cheating and acts in kind whilst live \n",
      "\n",
      "Title after cleaning: wonderfuel streamer accuses his girlfriend of cheating and acts in kind whilst live\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Preprocessing",
   "id": "a7aad30a3b7770d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T22:37:00.680758Z",
     "start_time": "2024-07-24T22:37:00.073063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['processed_title'] = df['cleaned_title'].apply(lambda title: preprocess_text(str(title)))\n",
    "df['processed_text'] = df['cleaned_text'].apply(lambda text: preprocess_text(str(text)))\n",
    "print(f'Title before token/lemmat-ization: {df[\"cleaned_title\"][0]} \\n\\nTitle after: {df[\"processed_title\"][0]}')\n"
   ],
   "id": "95ebda7b867b5fea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title before token/lemmat-ization: wonderfuel streamer accuses his girlfriend of cheating and acts in kind whilst live \n",
      "\n",
      "Title after: wonderfuel streamer accuses girlfriend cheating act kind whilst live\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Sentiment Analysis\n",
   "id": "514ca0b94191da4b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T22:38:46.036802Z",
     "start_time": "2024-07-24T22:37:59.520363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load pre-trained sentiment analysis model\n",
    "sentiment_model = pipeline(\"text-classification\",model='bhadresh-savani/distilbert-base-uncased-emotion', return_all_scores=True)\n"
   ],
   "id": "2de751ccc9027333",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf_model.h5:  55%|#####4    | 147M/268M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "03e203c8b3ba451989ac9b6c74fa7175"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at bhadresh-savani/distilbert-base-uncased-emotion.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/291 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bbafbc2f81f94bee8787fbdfa7eb4e27"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e41a75e39b640b9b8cd04e7d2a147c4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b4e9954bd59643ab882fa73aca7b2735"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilynorthcutt/Documents/Projects/redditHateSpeech/env/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T23:05:17.186981Z",
     "start_time": "2024-07-24T23:05:16.784713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --------- TITLE ------------\n",
    "# Apply sentiment analysis\n",
    "df_temp = df.iloc[0:10]\n",
    "df_temp['sentiment_title'] = df_temp['processed_title'].apply(lambda x: sentiment_model(x))\n",
    "\n",
    "# Convert list of list of labels with sentiments into dictionary where each sentiment is a key and their values are their scores\n",
    "test_list = list([])\n",
    "for row in range(0, len(df_temp['sentiment_title'])):\n",
    "  model_temp1 = df_temp['sentiment_title'][row]\n",
    "  test_dict = {}  \n",
    "  for i in range(0, len(model_temp1[0])):\n",
    "    model_temp2 = model_temp1[0][i]\n",
    "    test_dict[model_temp2[\"label\"]] = model_temp2[\"score\"]\n",
    "  test_list.append(test_dict)\n",
    "  \n",
    "df_temp['sentiment_title'] = test_list\n",
    "\n",
    "# Make each sentiment in the dictionary its own column\n",
    "df_temp.head()\n",
    "\n",
    "\n",
    "# --------- POST TEXT ------------\n"
   ],
   "id": "2ad5a285a7a3edd3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/qq0h5dqs29d1fxgph58vq8x80000gn/T/ipykernel_22783/4037132735.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['sentiment_title'] = df_temp['processed_title'].apply(lambda x: sentiment_model(x))\n",
      "/var/folders/dt/qq0h5dqs29d1fxgph58vq8x80000gn/T/ipykernel_22783/4037132735.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['sentiment_title'] = test_list\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                author created_utc  num_comments  \\\n",
       "0         maybethrowed  2017-11-03             0   \n",
       "1      IncelDegenerate  2017-11-03             0   \n",
       "2  TheOneAndOnlyDeggie  2017-11-03             0   \n",
       "3         BJRgaminggod  2017-11-03             0   \n",
       "4          FreshCope44  2017-11-03             0   \n",
       "\n",
       "                                            selftext subreddit  \\\n",
       "0                                                       Incels   \n",
       "1                                                       Incels   \n",
       "2                                                       Incels   \n",
       "3  I’m in high school and I get ready to take my ...    Incels   \n",
       "4                                          [removed]    Incels   \n",
       "\n",
       "                                               title  \\\n",
       "0  WONDERFUEL: Streamer accuses his girlfriend of...   \n",
       "1                                   Guide to Females   \n",
       "2                 Incel? Chad? Something in between?   \n",
       "3  VENT I white knighted for a girl in class beca...   \n",
       "4                                        Shame on me   \n",
       "\n",
       "                                       cleaned_title  \\\n",
       "0  wonderfuel streamer accuses his girlfriend of ...   \n",
       "1                                   guide to females   \n",
       "2                   incel chad something in between    \n",
       "3  vent i white knighted for a girl in class beca...   \n",
       "4                                        shame on me   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                                      \n",
       "3  i m in high school and i get ready to take my ...   \n",
       "4                                           removed    \n",
       "\n",
       "                                       prepped_title  \\\n",
       "0  wonderfuel streamer accuses girlfriend cheatin...   \n",
       "1                                       guide female   \n",
       "2                               incel chad something   \n",
       "3  vent white knighted girl class saw 2 bag hot c...   \n",
       "4                                              shame   \n",
       "\n",
       "                                        prepped_text  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                                      \n",
       "3  high school get ready take social study class ...   \n",
       "4                                            removed   \n",
       "\n",
       "                                     processed_title  \\\n",
       "0  wonderfuel streamer accuses girlfriend cheatin...   \n",
       "1                                       guide female   \n",
       "2                               incel chad something   \n",
       "3  vent white knighted girl class saw 2 bag hot c...   \n",
       "4                                              shame   \n",
       "\n",
       "                                      processed_text  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                                      \n",
       "3  high school get ready take social study class ...   \n",
       "4                                            removed   \n",
       "\n",
       "                                     sentiment_title  \n",
       "0  {'sadness': 0.0042288838885724545, 'joy': 0.00...  \n",
       "1  {'sadness': 0.05490565672516823, 'joy': 0.6465...  \n",
       "2  {'sadness': 0.021808000281453133, 'joy': 0.090...  \n",
       "3  {'sadness': 0.6625804305076599, 'joy': 0.01809...  \n",
       "4  {'sadness': 0.9164012670516968, 'joy': 0.00643...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>cleaned_title</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>prepped_title</th>\n",
       "      <th>prepped_text</th>\n",
       "      <th>processed_title</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>sentiment_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>maybethrowed</td>\n",
       "      <td>2017-11-03</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Incels</td>\n",
       "      <td>WONDERFUEL: Streamer accuses his girlfriend of...</td>\n",
       "      <td>wonderfuel streamer accuses his girlfriend of ...</td>\n",
       "      <td></td>\n",
       "      <td>wonderfuel streamer accuses girlfriend cheatin...</td>\n",
       "      <td></td>\n",
       "      <td>wonderfuel streamer accuses girlfriend cheatin...</td>\n",
       "      <td></td>\n",
       "      <td>{'sadness': 0.0042288838885724545, 'joy': 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IncelDegenerate</td>\n",
       "      <td>2017-11-03</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Incels</td>\n",
       "      <td>Guide to Females</td>\n",
       "      <td>guide to females</td>\n",
       "      <td></td>\n",
       "      <td>guide female</td>\n",
       "      <td></td>\n",
       "      <td>guide female</td>\n",
       "      <td></td>\n",
       "      <td>{'sadness': 0.05490565672516823, 'joy': 0.6465...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TheOneAndOnlyDeggie</td>\n",
       "      <td>2017-11-03</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Incels</td>\n",
       "      <td>Incel? Chad? Something in between?</td>\n",
       "      <td>incel chad something in between</td>\n",
       "      <td></td>\n",
       "      <td>incel chad something</td>\n",
       "      <td></td>\n",
       "      <td>incel chad something</td>\n",
       "      <td></td>\n",
       "      <td>{'sadness': 0.021808000281453133, 'joy': 0.090...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BJRgaminggod</td>\n",
       "      <td>2017-11-03</td>\n",
       "      <td>0</td>\n",
       "      <td>I’m in high school and I get ready to take my ...</td>\n",
       "      <td>Incels</td>\n",
       "      <td>VENT I white knighted for a girl in class beca...</td>\n",
       "      <td>vent i white knighted for a girl in class beca...</td>\n",
       "      <td>i m in high school and i get ready to take my ...</td>\n",
       "      <td>vent white knighted girl class saw 2 bag hot c...</td>\n",
       "      <td>high school get ready take social study class ...</td>\n",
       "      <td>vent white knighted girl class saw 2 bag hot c...</td>\n",
       "      <td>high school get ready take social study class ...</td>\n",
       "      <td>{'sadness': 0.6625804305076599, 'joy': 0.01809...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FreshCope44</td>\n",
       "      <td>2017-11-03</td>\n",
       "      <td>0</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>Incels</td>\n",
       "      <td>Shame on me</td>\n",
       "      <td>shame on me</td>\n",
       "      <td>removed</td>\n",
       "      <td>shame</td>\n",
       "      <td>removed</td>\n",
       "      <td>shame</td>\n",
       "      <td>removed</td>\n",
       "      <td>{'sadness': 0.9164012670516968, 'joy': 0.00643...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T22:48:51.540028Z",
     "start_time": "2024-07-24T22:48:51.482041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "title_temp = df['processed_title'][4]\n",
    "print(title_temp)\n",
    "model = sentiment_model(title_temp)\n",
    "model"
   ],
   "id": "96548698aaa17bc5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shame\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'label': 'sadness', 'score': 0.9164012670516968},\n",
       "  {'label': 'joy', 'score': 0.006433330476284027},\n",
       "  {'label': 'love', 'score': 0.0024321023374795914},\n",
       "  {'label': 'anger', 'score': 0.07191678136587143},\n",
       "  {'label': 'fear', 'score': 0.0016750693321228027},\n",
       "  {'label': 'surprise', 'score': 0.0011414638720452785}]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T22:57:57.086788Z",
     "start_time": "2024-07-24T22:57:57.082548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_list = list([])\n",
    "\n",
    "for row in range(0, len(model)):\n",
    "  model_temp1 = model[row]\n",
    "\n",
    "  test_dict = {}\n",
    "  for i in range(0, len(model_temp1)):\n",
    "    model_temp2 = model[row][i]\n",
    "    test_dict[model_temp2[\"label\"]] = model_temp2[\"score\"]\n",
    "    \n",
    "  test_list.append(test_dict)\n",
    "  \n",
    "test_list"
   ],
   "id": "90f003ce92c2f56e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sadness': 0.9164012670516968,\n",
       "  'joy': 0.006433330476284027,\n",
       "  'love': 0.0024321023374795914,\n",
       "  'anger': 0.07191678136587143,\n",
       "  'fear': 0.0016750693321228027,\n",
       "  'surprise': 0.0011414638720452785}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T22:52:53.262613Z",
     "start_time": "2024-07-24T22:52:53.260525Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b7a1bd4128c0400f",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T22:54:15.176833Z",
     "start_time": "2024-07-24T22:54:15.172812Z"
    }
   },
   "cell_type": "code",
   "source": "df.iloc[0:10][\"title\"]",
   "id": "eee3ca18cf0d5be4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    WONDERFUEL: Streamer accuses his girlfriend of...\n",
       "1                                     Guide to Females\n",
       "2                   Incel? Chad? Something in between?\n",
       "3    VENT I white knighted for a girl in class beca...\n",
       "4                                          Shame on me\n",
       "5                                      Catfish Request\n",
       "6                                               Always\n",
       "7    Something Awful forums are obsessed with r/incels\n",
       "8    Sex is the tool that the elites use to control...\n",
       "9    Take the Whitepill. Everyone here needs to rea...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c823d36b30271063"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
